{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RWDC4Q5RsXC"
      },
      "source": [
        "# pytorch-compress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk-R-bErR7gS"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/byronknoll/pytorch-compress/blob/master/pytorch-compress.ipynb)\n",
        "\n",
        "Made by Byron Knoll. GitHub repository: https://github.com/byronknoll/pytorch-compress\n",
        "\n",
        "### Description\n",
        "\n",
        "This is a PyTorch port of [tensorflow-compress](https://github.com/byronknoll/tensorflow-compress). pytorch-compress performs lossless data compression using LSTM.\n",
        "\n",
        "Feel free to contact me at byron@byronknoll.com if you have any questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ5gF5mLs0Ew"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUc1x3vIs4hF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "batch_size = 64 #@param {type:\"integer\"}\n",
        "#@markdown >_This will split the file into N batches, and process them in parallel. Increasing this will improve speed but can make compression rate worse. Make this a multiple of 8 to improve speed on certain GPUs._\n",
        "seq_length = 6 #@param {type:\"integer\"}\n",
        "#@markdown >_This determines the horizon for back propagation through time. Reducing this will improve speed, but can make compression rate worse._\n",
        "num_layers=4 #@param {type:\"integer\"}\n",
        "emb_size=512 #@param {type:\"integer\"}\n",
        "hidden_size=512 #@param {type:\"integer\"}\n",
        "learning_rate = 0.0005 #@param {type:\"number\"}\n",
        "mode = 'compress' #@param [\"compress\", \"decompress\", \"both\", \"preprocess_only\"]\n",
        "#@markdown >_Whether to run compression only, decompression only, or both. \"preprocess_only\" will only run preprocessing and skip compression._\n",
        "preprocess = 'nncp-done' #@param [\"cmix\", \"nncp\", \"nncp-done\", \"none\"]\n",
        "#@markdown >_The choice of preprocessor. NNCP works better on enwik8/enwik9. NNCP preprocessing is slower since it constructs a custom dictionary, while cmix uses a pretrained dictionary. \"nncp_done\" is used for files which have already been preprocessed by NNCP (the dictionary must also be included)._\n",
        "n_words = 8192 #@param {type:\"integer\"}\n",
        "#@markdown >_Only used for NNCP preprocessor: this is the approximative maximum number of words of the dictionary. Recommended value for enwik8/enwik9: 8192._\n",
        "min_freq = 64 #@param {type:\"integer\"}\n",
        "#@markdown >_Only used for NNCP preprocessor: this is the minimum frequency of the selected words. Recommended value for enwik8: 64, enwik9: 512._\n",
        "path_to_file = \"custom\" #@param [\"enwik4\", \"enwik6\", \"enwik8\", \"enwik9\", \"custom\"]\n",
        "#@markdown >_Name of the file to compress or decompress. If \"custom\" is selected, use the next parameter to set a custom path._\n",
        "custom_path = 'enwik8.dat' #@param {type:\"string\"}\n",
        "#@markdown >_Use this if the previous parameter was set to \"custom\". Set this to the name of the file you want to compress/decompress. You can transfer files using the \"http_path\" or \"local_upload\" options below._\n",
        "http_path = 'https://drive.google.com/uc?id=141rhIywiBSZK_cOZ1efgobMuMyXkeNgy https://drive.google.com/uc?id=15eJ8Byiqy0Svf9LOYDQ9IMphZCYhb3y3' #@param {type:\"string\"}\n",
        "#@markdown >_The file from this URL will be downloaded. It is recommended to use Google Drive URLs to get fast transfer speed. Use this format for Google Drive files: https://drive.google.com/uc?id= and paste the file ID at the end of the URL. You can find the file ID from the \"Get Link\" URL in Google Drive. You can enter multiple URLs here, space separated._\n",
        "local_upload = False #@param {type:\"boolean\"}\n",
        "#@markdown >_If enabled, you will be prompted in the \"Setup Files\" section to select files to upload from your local computer. You can upload multiple files. Note: the upload speed can be quite slow (use \"http_path\" for better transfer speeds)._\n",
        "download_option = \"no_download\" #@param [\"no_download\", \"local\", \"google_drive\"]\n",
        "#@markdown >_If this is set to \"local\", the output files will be downloaded to your computer after compression/decompression. If set to \"google_drive\", they will be copied to your Google Drive account (which is significantly faster than downloading locally)._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yezcaYiWzhoV"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtRgaznIzneg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import files\n",
        "import time\n",
        "import math\n",
        "import sys\n",
        "import subprocess\n",
        "import contextlib\n",
        "import os\n",
        "import scipy\n",
        "from google.colab import drive\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2795ZUv4BPQi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title System Info\n",
        "\n",
        "def system_info():\n",
        "  \"\"\"Prints out system information.\"\"\"\n",
        "  gpu_info = !nvidia-smi\n",
        "  gpu_info = '\\n'.join(gpu_info)\n",
        "  if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "  else:\n",
        "    print(gpu_info)\n",
        "  !lscpu |grep 'Model name'\n",
        "  !cat /proc/meminfo | head -n 3\n",
        "\n",
        "system_info()\n",
        "print(\"PyTorch: \" + torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8TjO6DWgoA7i"
      },
      "outputs": [],
      "source": [
        "#@title Mount Google Drive\n",
        "if download_option == \"google_drive\":\n",
        "  drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8FL-Z7yMU4FF"
      },
      "outputs": [],
      "source": [
        "#@title Setup Files\n",
        "\n",
        "!mkdir -p \"data\"\n",
        "\n",
        "if local_upload:\n",
        "  %cd data\n",
        "  files.upload()\n",
        "  %cd ..\n",
        "\n",
        "if path_to_file == 'enwik8' or path_to_file == 'enwik6' or path_to_file == 'enwik4':\n",
        "  %cd data\n",
        "  !gdown --id 11-twesB-vGexGZpVSFbaCZDXKh5jMmMd\n",
        "  !head -c 1000000 enwik8 > enwik6\n",
        "  !head -c 10000 enwik8 > enwik4\n",
        "  path_to_file = 'data/' + path_to_file\n",
        "  %cd ..\n",
        "\n",
        "if path_to_file == 'enwik9':\n",
        "  %cd data\n",
        "  !gdown --id 1D2gCmf9AlXIBP62ARhy0XcIuIolOTRAE\n",
        "  !unzip enwik9.zip\n",
        "  path_to_file = 'data/' + path_to_file\n",
        "  %cd ..\n",
        "\n",
        "if path_to_file == 'custom':\n",
        "  path_to_file = 'data/' + custom_path\n",
        "\n",
        "if http_path:\n",
        "  %cd data\n",
        "  paths = http_path.split()\n",
        "  for path in paths:\n",
        "    !gdown $path\n",
        "  %cd ..\n",
        "\n",
        "if preprocess == 'cmix':\n",
        "  !gdown --id 1qa7K28tlUDs9GGYbaL_iE9M4m0L1bYm9\n",
        "  !unzip cmix-v18.zip\n",
        "  %cd cmix\n",
        "  !make\n",
        "  %cd ..\n",
        "\n",
        "if preprocess == 'nncp' or preprocess == 'nncp-done':\n",
        "  !gdown --id 1EzVPbRkBIIbgOzvEMeM0YpibDi2R4SHD\n",
        "  !tar -xf nncp-2019-11-16.tar.gz\n",
        "  %cd nncp-2019-11-16/\n",
        "  !make preprocess\n",
        "  %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ZRPnh-2dCz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Model Architecture\n",
        "\n",
        "class LSTM1(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "        super(LSTM1, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(num_classes, emb_size)\n",
        "        self.lstm = nn.LSTM(input_size=emb_size, hidden_size=hidden_size,\n",
        "                          num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size*num_layers, num_classes)\n",
        "\n",
        "    def forward(self, x, h_0, c_0):\n",
        "      embeds = self.word_embeddings(x)\n",
        "      output, (hn, cn) = self.lstm(embeds, (h_0, c_0))\n",
        "      out = self.fc(torch.transpose(hn, 0, 1).reshape(batch_size, -1))\n",
        "      return (out, hn.clone().detach(), cn.clone().detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlytnNHdfbIM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Compression Library\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "def get_symbol(index, length, freq, coder, compress, data):\n",
        "  \"\"\"Runs arithmetic coding and returns the next symbol.\n",
        "\n",
        "  Args:\n",
        "    index: Int, position of the symbol in the file.\n",
        "    length: Int, size limit of the file.\n",
        "    freq: ndarray, predicted symbol probabilities.\n",
        "    coder: this is the arithmetic coder.\n",
        "    compress: Boolean, True if compressing, False if decompressing.\n",
        "    data: List containing each symbol in the file.\n",
        "\n",
        "  Returns:\n",
        "    The next symbol, or 0 if \"index\" is over the file size limit.\n",
        "  \"\"\"\n",
        "  symbol = 0\n",
        "  if index < length:\n",
        "    if compress:\n",
        "      symbol = data[index]\n",
        "      coder.write(freq, symbol)\n",
        "    else:\n",
        "      symbol = coder.read(freq)\n",
        "      data[index] = symbol\n",
        "  return symbol\n",
        "\n",
        "def train(pos, seq_input, length, vocab_size, coder, model, optimizer, compress,\n",
        "          data, loss_function, scaler, states):\n",
        "  \"\"\"Runs one training step.\n",
        "\n",
        "  Args:\n",
        "    pos: Int, position in the file for the current symbol for the *first* batch.\n",
        "    seq_input: Tensor, containing the last seq_length inputs for the model.\n",
        "    length: Int, size limit of the file.\n",
        "    vocab_size: Int, size of the vocabulary.\n",
        "    coder: this is the arithmetic coder.\n",
        "    model: the model to generate predictions.\n",
        "    optimizer: optimizer used to train the model.\n",
        "    compress: Boolean, True if compressing, False if decompressing.\n",
        "    data: List containing each symbol in the file.\n",
        "\n",
        "  Returns:\n",
        "    seq_input: Tensor, containing the last seq_length inputs for the model.\n",
        "    cross_entropy: cross entropy numerator.\n",
        "    denom: cross entropy denominator.\n",
        "  \"\"\"\n",
        "  loss = cross_entropy = denom = 0\n",
        "  split = math.ceil(length / batch_size)\n",
        "\n",
        "  # Run the model (for all batches in parallel) to get predictions for the\n",
        "  # next characters.\n",
        "  state = states.pop(0)\n",
        "  (logits, h_final, c_final) = model(seq_input, state[0], state[1])\n",
        "  states.append([h_final, c_final])\n",
        "  p = logits.detach().cpu().numpy()\n",
        "  symbols = []\n",
        "  # When the last batch reaches the end of the file, we start giving it \"0\"\n",
        "  # as input. We use a mask to prevent this from influencing the gradients.\n",
        "  mask = []\n",
        "  # Go over each batch to run the arithmetic coding and prepare the next\n",
        "  # input.\n",
        "  for i in range(batch_size):\n",
        "    # The \"10000000\" is used to convert floats into large integers (since\n",
        "    # the arithmetic coder works on integers).\n",
        "    soft = scipy.special.softmax(p[i])\n",
        "    freq = np.cumsum(soft * 10000000 + 1)\n",
        "    index = pos + 1 + i * split\n",
        "    symbol = get_symbol(index, length, freq, coder, compress, data)\n",
        "    symbols.append(symbol)\n",
        "    if index < length:\n",
        "      prob = soft[symbol]\n",
        "      if prob <= 0:\n",
        "        # Set a small value to avoid error with log2.\n",
        "        prob = 0.000001\n",
        "      cross_entropy += math.log2(prob)\n",
        "      denom += 1\n",
        "      mask.append(1.0)\n",
        "    else:\n",
        "      mask.append(0.0)\n",
        "  # \"symbols\" will be used both for the loss function and for the next\n",
        "  # input.\n",
        "  input_one_hot = torch.nn.functional.one_hot(torch.LongTensor(symbols), num_classes=vocab_size).float().cuda()\n",
        "  loss = loss_function(logits, input_one_hot) #* torch.tensor(mask).cuda()\n",
        "  # Remove the oldest input and append the new one.\n",
        "  seq_input = seq_input[:, 1:]\n",
        "  seq_input = torch.cat((seq_input, torch.LongTensor(symbols).unsqueeze(1).cuda()), dim=1)\n",
        "  # Run the backwards pass to update model weights.\n",
        "  scaler.scale(loss).backward()\n",
        "  scaler.unscale_(optimizer)\n",
        "  torch.nn.utils.clip_grad_norm_(model.parameters(), 4)\n",
        "  scaler.step(optimizer)\n",
        "  scaler.update()\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  return (seq_input, cross_entropy, denom)\n",
        "\n",
        "def reset_seed():\n",
        "  \"\"\"Initializes various random seeds to help with determinism.\"\"\"\n",
        "  SEED = 1234\n",
        "  os.environ['PYTHONHASHSEED']=str(SEED)\n",
        "  random.seed(SEED)\n",
        "  np.random.seed(SEED)\n",
        "  torch.manual_seed(SEED)\n",
        "\n",
        "def download(path):\n",
        "  \"\"\"Downloads the file at the specified path.\"\"\"\n",
        "  if download_option == 'local':\n",
        "    files.download(path)\n",
        "  elif download_option == 'google_drive':\n",
        "    !cp -f $path /content/gdrive/My\\ Drive\n",
        "\n",
        "def process(compress, length, vocab_size, coder, data):\n",
        "  \"\"\"This runs compression/decompression.\n",
        "\n",
        "  Args:\n",
        "    compress: Boolean, True if compressing, False if decompressing.\n",
        "    length: Int, size limit of the file.\n",
        "    vocab_size: Int, size of the vocabulary.\n",
        "    coder: this is the arithmetic coder.\n",
        "    data: List containing each symbol in the file.\n",
        "  \"\"\"\n",
        "  start = time.time()\n",
        "  reset_seed()\n",
        "  vocab_size=64*math.ceil(vocab_size/64)\n",
        "  model = LSTM1(vocab_size, vocab_size, hidden_size, num_layers, seq_length).cuda()\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  # TODO: load model from checkpoint.\n",
        "  print(model)\n",
        "  dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
        "\n",
        "  # Try to split the file into equal size pieces for the different batches. The\n",
        "  # last batch may have fewer characters if the file can't be split equally.\n",
        "  split = math.ceil(length / batch_size)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0, eps=1e-5, betas=(0, 0.9999))\n",
        "\n",
        "  # Use a uniform distribution for predicting the first batch of symbols. The\n",
        "  # \"10000000\" is used to convert floats into large integers (since the\n",
        "  # arithmetic coder works on integers).\n",
        "  freq = np.cumsum(np.full(vocab_size, (1.0 / vocab_size)) * 10000000 + 1)\n",
        "  # Construct the first set of input characters for training.\n",
        "  symbols = []\n",
        "  for i in range(batch_size):\n",
        "    symbols.append(get_symbol(i*split, length, freq, coder, compress, data))\n",
        "  # Replicate the input tensor seq_length times, to match the input format.\n",
        "  symbols_expanded = torch.LongTensor(symbols).unsqueeze(1)\n",
        "  seq_input = symbols_expanded.repeat(1, seq_length).cuda()\n",
        "  pos = cross_entropy = denom = last_output = 0\n",
        "  template = '{:0.2f}%\\tcross entropy: {:0.2f}\\ttime: {:0.2f}'\n",
        "  # This will keep track of layer states. Initialize them to zeros.\n",
        "  states = []\n",
        "  for i in range(seq_length):\n",
        "    h_0 = torch.zeros(num_layers, batch_size, hidden_size).cuda() #hidden state\n",
        "    c_0 = torch.zeros(num_layers, batch_size, hidden_size).cuda() #internal state\n",
        "    states.append([h_0, c_0])\n",
        "  # Keep repeating the training step until we get to the end of the file.\n",
        "  while pos < split:\n",
        "    seq_input, ce, d = train(pos, seq_input, length, vocab_size, coder, model,\n",
        "                             optimizer, compress, data, loss_function, scaler, states)\n",
        "    cross_entropy += ce\n",
        "    denom += d\n",
        "    pos += 1\n",
        "    time_diff = time.time() - start\n",
        "    # If it has been over 20 seconds since the last status message, display a\n",
        "    # new one.\n",
        "    if time_diff - last_output > 20:\n",
        "      last_output = time_diff\n",
        "      percentage = 100 * pos / split\n",
        "      if percentage >= 100: continue\n",
        "      print(template.format(percentage, -cross_entropy / denom, time_diff))\n",
        "  if compress:\n",
        "    coder.finish()\n",
        "  print(template.format(100, -cross_entropy / length, time.time() - start))\n",
        "  system_info()\n",
        "  print(\"Compressed size:\", os.path.getsize(path_to_file))\n",
        "  # TODO: save model weights to checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6WEbfVSEKilf"
      },
      "outputs": [],
      "source": [
        "#@title Arithmetic Coding Library\n",
        "\n",
        "#\n",
        "# Reference arithmetic coding\n",
        "# Copyright (c) Project Nayuki\n",
        "#\n",
        "# https://www.nayuki.io/page/reference-arithmetic-coding\n",
        "# https://github.com/nayuki/Reference-arithmetic-coding\n",
        "#\n",
        "\n",
        "import sys\n",
        "python3 = sys.version_info.major >= 3\n",
        "\n",
        "\n",
        "# ---- Arithmetic coding core classes ----\n",
        "\n",
        "# Provides the state and behaviors that arithmetic coding encoders and decoders share.\n",
        "class ArithmeticCoderBase(object):\n",
        "\n",
        "\t# Constructs an arithmetic coder, which initializes the code range.\n",
        "\tdef __init__(self, numbits):\n",
        "\t\tif numbits < 1:\n",
        "\t\t\traise ValueError(\"State size out of range\")\n",
        "\n",
        "\t\t# -- Configuration fields --\n",
        "\t\t# Number of bits for the 'low' and 'high' state variables. Must be at least 1.\n",
        "\t\t# - Larger values are generally better - they allow a larger maximum frequency total (maximum_total),\n",
        "\t\t#   and they reduce the approximation error inherent in adapting fractions to integers;\n",
        "\t\t#   both effects reduce the data encoding loss and asymptotically approach the efficiency\n",
        "\t\t#   of arithmetic coding using exact fractions.\n",
        "\t\t# - But larger state sizes increase the computation time for integer arithmetic,\n",
        "\t\t#   and compression gains beyond ~30 bits essentially zero in real-world applications.\n",
        "\t\t# - Python has native bigint arithmetic, so there is no upper limit to the state size.\n",
        "\t\t#   For Java and C++ where using native machine-sized integers makes the most sense,\n",
        "\t\t#   they have a recommended value of num_state_bits=32 as the most versatile setting.\n",
        "\t\tself.num_state_bits = numbits\n",
        "\t\t# Maximum range (high+1-low) during coding (trivial), which is 2^num_state_bits = 1000...000.\n",
        "\t\tself.full_range = 1 << self.num_state_bits\n",
        "\t\t# The top bit at width num_state_bits, which is 0100...000.\n",
        "\t\tself.half_range = self.full_range >> 1  # Non-zero\n",
        "\t\t# The second highest bit at width num_state_bits, which is 0010...000. This is zero when num_state_bits=1.\n",
        "\t\tself.quarter_range = self.half_range >> 1  # Can be zero\n",
        "\t\t# Minimum range (high+1-low) during coding (non-trivial), which is 0010...010.\n",
        "\t\tself.minimum_range = self.quarter_range + 2  # At least 2\n",
        "\t\t# Maximum allowed total from a frequency table at all times during coding. This differs from Java\n",
        "\t\t# and C++ because Python's native bigint avoids constraining the size of intermediate computations.\n",
        "\t\tself.maximum_total = self.minimum_range\n",
        "\t\t# Bit mask of num_state_bits ones, which is 0111...111.\n",
        "\t\tself.state_mask = self.full_range - 1\n",
        "\n",
        "\t\t# -- State fields --\n",
        "\t\t# Low end of this arithmetic coder's current range. Conceptually has an infinite number of trailing 0s.\n",
        "\t\tself.low = 0\n",
        "\t\t# High end of this arithmetic coder's current range. Conceptually has an infinite number of trailing 1s.\n",
        "\t\tself.high = self.state_mask\n",
        "\n",
        "\n",
        "\t# Updates the code range (low and high) of this arithmetic coder as a result\n",
        "\t# of processing the given symbol with the given frequency table.\n",
        "\t# Invariants that are true before and after encoding/decoding each symbol\n",
        "\t# (letting full_range = 2^num_state_bits):\n",
        "\t# - 0 <= low <= code <= high < full_range. ('code' exists only in the decoder.)\n",
        "\t#   Therefore these variables are unsigned integers of num_state_bits bits.\n",
        "\t# - low < 1/2 * full_range <= high.\n",
        "\t#   In other words, they are in different halves of the full range.\n",
        "\t# - (low < 1/4 * full_range) || (high >= 3/4 * full_range).\n",
        "\t#   In other words, they are not both in the middle two quarters.\n",
        "\t# - Let range = high - low + 1, then full_range/4 < minimum_range\n",
        "\t#   <= range <= full_range. These invariants for 'range' essentially\n",
        "\t#   dictate the maximum total that the incoming frequency table can have.\n",
        "\tdef update(self, freqs, symbol):\n",
        "\t\t# State check\n",
        "\t\tlow = self.low\n",
        "\t\thigh = self.high\n",
        "\t\t# if low >= high or (low & self.state_mask) != low or (high & self.state_mask) != high:\n",
        "\t\t# \traise AssertionError(\"Low or high out of range\")\n",
        "\t\trange = high - low + 1\n",
        "\t\t# if not (self.minimum_range <= range <= self.full_range):\n",
        "\t\t# \traise AssertionError(\"Range out of range\")\n",
        "\n",
        "\t\t# Frequency table values check\n",
        "\t\ttotal = int(freqs[-1])\n",
        "\t\tsymlow = int(freqs[symbol-1]) if symbol > 0 else 0\n",
        "\t\tsymhigh = int(freqs[symbol])\n",
        "\t\t#total = freqs.get_total()\n",
        "\t\t#symlow = freqs.get_low(symbol)\n",
        "\t\t#symhigh = freqs.get_high(symbol)\n",
        "\t\t# if symlow == symhigh:\n",
        "\t\t# \traise ValueError(\"Symbol has zero frequency\")\n",
        "\t\t# if total > self.maximum_total:\n",
        "\t\t# \traise ValueError(\"Cannot code symbol because total is too large\")\n",
        "\n",
        "\t\t# Update range\n",
        "\t\tnewlow  = low + symlow  * range // total\n",
        "\t\tnewhigh = low + symhigh * range // total - 1\n",
        "\t\tself.low = newlow\n",
        "\t\tself.high = newhigh\n",
        "\n",
        "\t\t# While low and high have the same top bit value, shift them out\n",
        "\t\twhile ((self.low ^ self.high) & self.half_range) == 0:\n",
        "\t\t\tself.shift()\n",
        "\t\t\tself.low  = ((self.low  << 1) & self.state_mask)\n",
        "\t\t\tself.high = ((self.high << 1) & self.state_mask) | 1\n",
        "\t\t# Now low's top bit must be 0 and high's top bit must be 1\n",
        "\n",
        "\t\t# While low's top two bits are 01 and high's are 10, delete the second highest bit of both\n",
        "\t\twhile (self.low & ~self.high & self.quarter_range) != 0:\n",
        "\t\t\tself.underflow()\n",
        "\t\t\tself.low = (self.low << 1) ^ self.half_range\n",
        "\t\t\tself.high = ((self.high ^ self.half_range) << 1) | self.half_range | 1\n",
        "\n",
        "\n",
        "\t# Called to handle the situation when the top bit of 'low' and 'high' are equal.\n",
        "\tdef shift(self):\n",
        "\t\traise NotImplementedError()\n",
        "\n",
        "\n",
        "\t# Called to handle the situation when low=01(...) and high=10(...).\n",
        "\tdef underflow(self):\n",
        "\t\traise NotImplementedError()\n",
        "\n",
        "\n",
        "# Encodes symbols and writes to an arithmetic-coded bit stream.\n",
        "class ArithmeticEncoder(ArithmeticCoderBase):\n",
        "\n",
        "\t# Constructs an arithmetic coding encoder based on the given bit output stream.\n",
        "\tdef __init__(self, numbits, bitout):\n",
        "\t\tsuper(ArithmeticEncoder, self).__init__(numbits)\n",
        "\t\t# The underlying bit output stream.\n",
        "\t\tself.output = bitout\n",
        "\t\t# Number of saved underflow bits. This value can grow without bound.\n",
        "\t\tself.num_underflow = 0\n",
        "\n",
        "\n",
        "\t# Encodes the given symbol based on the given frequency table.\n",
        "\t# This updates this arithmetic coder's state and may write out some bits.\n",
        "\tdef write(self, freqs, symbol):\n",
        "\t\tself.update(freqs, symbol)\n",
        "\n",
        "\n",
        "\t# Terminates the arithmetic coding by flushing any buffered bits, so that the output can be decoded properly.\n",
        "\t# It is important that this method must be called at the end of the each encoding process.\n",
        "\t# Note that this method merely writes data to the underlying output stream but does not close it.\n",
        "\tdef finish(self):\n",
        "\t\tself.output.write(1)\n",
        "\n",
        "\n",
        "\tdef shift(self):\n",
        "\t\tbit = self.low >> (self.num_state_bits - 1)\n",
        "\t\tself.output.write(bit)\n",
        "\n",
        "\t\t# Write out the saved underflow bits\n",
        "\t\tfor _ in range(self.num_underflow):\n",
        "\t\t\tself.output.write(bit ^ 1)\n",
        "\t\tself.num_underflow = 0\n",
        "\n",
        "\n",
        "\tdef underflow(self):\n",
        "\t\tself.num_underflow += 1\n",
        "\n",
        "\n",
        "# Reads from an arithmetic-coded bit stream and decodes symbols.\n",
        "class ArithmeticDecoder(ArithmeticCoderBase):\n",
        "\n",
        "\t# Constructs an arithmetic coding decoder based on the\n",
        "\t# given bit input stream, and fills the code bits.\n",
        "\tdef __init__(self, numbits, bitin):\n",
        "\t\tsuper(ArithmeticDecoder, self).__init__(numbits)\n",
        "\t\t# The underlying bit input stream.\n",
        "\t\tself.input = bitin\n",
        "\t\t# The current raw code bits being buffered, which is always in the range [low, high].\n",
        "\t\tself.code = 0\n",
        "\t\tfor _ in range(self.num_state_bits):\n",
        "\t\t\tself.code = self.code << 1 | self.read_code_bit()\n",
        "\n",
        "\n",
        "\t# Decodes the next symbol based on the given frequency table and returns it.\n",
        "\t# Also updates this arithmetic coder's state and may read in some bits.\n",
        "\tdef read(self, freqs):\n",
        "\t\t#if not isinstance(freqs, CheckedFrequencyTable):\n",
        "\t\t#\tfreqs = CheckedFrequencyTable(freqs)\n",
        "\n",
        "\t\t# Translate from coding range scale to frequency table scale\n",
        "\t\ttotal = int(freqs[-1])\n",
        "\t\t#total = freqs.get_total()\n",
        "\t\t#if total > self.maximum_total:\n",
        "\t\t#\traise ValueError(\"Cannot decode symbol because total is too large\")\n",
        "\t\trange = self.high - self.low + 1\n",
        "\t\toffset = self.code - self.low\n",
        "\t\tvalue = ((offset + 1) * total - 1) // range\n",
        "\t\t#assert value * range // total <= offset\n",
        "\t\t#assert 0 <= value < total\n",
        "\n",
        "\t\t# A kind of binary search. Find highest symbol such that freqs.get_low(symbol) <= value.\n",
        "\t\tstart = 0\n",
        "\t\tend = len(freqs)\n",
        "\t\t#end = freqs.get_symbol_limit()\n",
        "\t\twhile end - start > 1:\n",
        "\t\t\tmiddle = (start + end) >> 1\n",
        "\t\t\tlow = int(freqs[middle-1]) if middle > 0 else 0\n",
        "\t\t\t#if freqs.get_low(middle) > value:\n",
        "\t\t\tif low > value:\n",
        "\t\t\t\tend = middle\n",
        "\t\t\telse:\n",
        "\t\t\t\tstart = middle\n",
        "\t\t#assert start + 1 == end\n",
        "\n",
        "\t\tsymbol = start\n",
        "\t\t#assert freqs.get_low(symbol) * range // total <= offset < freqs.get_high(symbol) * range // total\n",
        "\t\tself.update(freqs, symbol)\n",
        "\t\t#if not (self.low <= self.code <= self.high):\n",
        "\t\t#\traise AssertionError(\"Code out of range\")\n",
        "\t\treturn symbol\n",
        "\n",
        "\n",
        "\tdef shift(self):\n",
        "\t\tself.code = ((self.code << 1) & self.state_mask) | self.read_code_bit()\n",
        "\n",
        "\n",
        "\tdef underflow(self):\n",
        "\t\tself.code = (self.code & self.half_range) | ((self.code << 1) & (self.state_mask >> 1)) | self.read_code_bit()\n",
        "\n",
        "\n",
        "\t# Returns the next bit (0 or 1) from the input stream. The end\n",
        "\t# of stream is treated as an infinite number of trailing zeros.\n",
        "\tdef read_code_bit(self):\n",
        "\t\ttemp = self.input.read()\n",
        "\t\tif temp == -1:\n",
        "\t\t\ttemp = 0\n",
        "\t\treturn temp\n",
        "\n",
        "\n",
        "# ---- Bit-oriented I/O streams ----\n",
        "\n",
        "# A stream of bits that can be read. Because they come from an underlying byte stream,\n",
        "# the total number of bits is always a multiple of 8. The bits are read in big endian.\n",
        "class BitInputStream(object):\n",
        "\n",
        "\t# Constructs a bit input stream based on the given byte input stream.\n",
        "\tdef __init__(self, inp):\n",
        "\t\t# The underlying byte stream to read from\n",
        "\t\tself.input = inp\n",
        "\t\t# Either in the range [0x00, 0xFF] if bits are available, or -1 if end of stream is reached\n",
        "\t\tself.currentbyte = 0\n",
        "\t\t# Number of remaining bits in the current byte, always between 0 and 7 (inclusive)\n",
        "\t\tself.numbitsremaining = 0\n",
        "\n",
        "\n",
        "\t# Reads a bit from this stream. Returns 0 or 1 if a bit is available, or -1 if\n",
        "\t# the end of stream is reached. The end of stream always occurs on a byte boundary.\n",
        "\tdef read(self):\n",
        "\t\tif self.currentbyte == -1:\n",
        "\t\t\treturn -1\n",
        "\t\tif self.numbitsremaining == 0:\n",
        "\t\t\ttemp = self.input.read(1)\n",
        "\t\t\tif len(temp) == 0:\n",
        "\t\t\t\tself.currentbyte = -1\n",
        "\t\t\t\treturn -1\n",
        "\t\t\tself.currentbyte = temp[0] if python3 else ord(temp)\n",
        "\t\t\tself.numbitsremaining = 8\n",
        "\t\tassert self.numbitsremaining > 0\n",
        "\t\tself.numbitsremaining -= 1\n",
        "\t\treturn (self.currentbyte >> self.numbitsremaining) & 1\n",
        "\n",
        "\n",
        "\t# Reads a bit from this stream. Returns 0 or 1 if a bit is available, or raises an EOFError\n",
        "\t# if the end of stream is reached. The end of stream always occurs on a byte boundary.\n",
        "\tdef read_no_eof(self):\n",
        "\t\tresult = self.read()\n",
        "\t\tif result != -1:\n",
        "\t\t\treturn result\n",
        "\t\telse:\n",
        "\t\t\traise EOFError()\n",
        "\n",
        "\n",
        "\t# Closes this stream and the underlying input stream.\n",
        "\tdef close(self):\n",
        "\t\tself.input.close()\n",
        "\t\tself.currentbyte = -1\n",
        "\t\tself.numbitsremaining = 0\n",
        "\n",
        "\n",
        "# A stream where bits can be written to. Because they are written to an underlying\n",
        "# byte stream, the end of the stream is padded with 0's up to a multiple of 8 bits.\n",
        "# The bits are written in big endian.\n",
        "class BitOutputStream(object):\n",
        "\n",
        "\t# Constructs a bit output stream based on the given byte output stream.\n",
        "\tdef __init__(self, out):\n",
        "\t\tself.output = out  # The underlying byte stream to write to\n",
        "\t\tself.currentbyte = 0  # The accumulated bits for the current byte, always in the range [0x00, 0xFF]\n",
        "\t\tself.numbitsfilled = 0  # Number of accumulated bits in the current byte, always between 0 and 7 (inclusive)\n",
        "\n",
        "\n",
        "\t# Writes a bit to the stream. The given bit must be 0 or 1.\n",
        "\tdef write(self, b):\n",
        "\t\tif b not in (0, 1):\n",
        "\t\t\traise ValueError(\"Argument must be 0 or 1\")\n",
        "\t\tself.currentbyte = (self.currentbyte << 1) | b\n",
        "\t\tself.numbitsfilled += 1\n",
        "\t\tif self.numbitsfilled == 8:\n",
        "\t\t\ttowrite = bytes((self.currentbyte,)) if python3 else chr(self.currentbyte)\n",
        "\t\t\tself.output.write(towrite)\n",
        "\t\t\tself.currentbyte = 0\n",
        "\t\t\tself.numbitsfilled = 0\n",
        "\n",
        "\n",
        "\t# Closes this stream and the underlying output stream. If called when this\n",
        "\t# bit stream is not at a byte boundary, then the minimum number of \"0\" bits\n",
        "\t# (between 0 and 7 of them) are written as padding to reach the next byte boundary.\n",
        "\tdef close(self):\n",
        "\t\twhile self.numbitsfilled != 0:\n",
        "\t\t\tself.write(0)\n",
        "\t\tself.output.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjEj_H_Pz1vr"
      },
      "source": [
        "## Compress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jZ5Dga8hMsO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Preprocess\n",
        "\n",
        "if mode != 'decompress':\n",
        "  input_path = path_to_file\n",
        "\n",
        "  if preprocess == 'cmix':\n",
        "    !./cmix/cmix -s ./cmix/dictionary/english.dic $path_to_file ./data/preprocessed.dat\n",
        "    input_path = \"./data/preprocessed.dat\"\n",
        "\n",
        "  # int_list will contain the characters of the file.\n",
        "  int_list = []\n",
        "  if preprocess == 'nncp' or preprocess == 'nncp-done':\n",
        "    if preprocess == 'nncp':\n",
        "      !time ./nncp-2019-11-16/preprocess c data/dictionary.words $path_to_file data/preprocessed.dat $n_words $min_freq\n",
        "    else:\n",
        "      !cp $path_to_file data/preprocessed.dat\n",
        "    input_path = \"./data/preprocessed.dat\"\n",
        "    orig = open(input_path, 'rb').read()\n",
        "    for i in range(0, len(orig), 2):\n",
        "      int_list.append(orig[i] * 256 + orig[i+1])\n",
        "    vocab_size = int(subprocess.check_output(\n",
        "        ['wc', '-l', 'data/dictionary.words']).split()[0])\n",
        "  else:\n",
        "    text = open(input_path, 'rb').read()\n",
        "    vocab = sorted(set(text))\n",
        "    vocab_size = len(vocab)\n",
        "    # Creating a mapping from unique characters to indexes.\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    for idx, c in enumerate(text):\n",
        "      int_list.append(char2idx[c])\n",
        "\n",
        "  # Round up to a multiple of 8 to improve performance.\n",
        "  vocab_size = math.ceil(vocab_size/8) * 8\n",
        "  file_len = len(int_list)\n",
        "  print ('Length of file: {} symbols'.format(file_len))\n",
        "  print ('Vocabulary size: {}'.format(vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ_3o0ZeEKcR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Compression\n",
        "\n",
        "if mode == 'compress' or mode == 'both':\n",
        "  original_file = path_to_file\n",
        "  path_to_file = \"data/compressed.dat\"\n",
        "  with open(path_to_file, \"wb\") as out, contextlib.closing(BitOutputStream(out)) as bitout:\n",
        "    length = len(int_list)\n",
        "    # Write the original file length to the compressed file header.\n",
        "    out.write(length.to_bytes(5, byteorder='big', signed=False))\n",
        "    if preprocess != 'nncp' and preprocess != 'nncp-done':\n",
        "      # If NNCP was not used for preprocessing, write 256 bits to the compressed\n",
        "      # file header to keep track of the vocabulary.\n",
        "      for i in range(256):\n",
        "        if i in char2idx:\n",
        "          bitout.write(1)\n",
        "        else:\n",
        "          bitout.write(0)\n",
        "    enc = ArithmeticEncoder(32, bitout)\n",
        "    process(True, length, vocab_size, enc, int_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEmm5PznEk5q",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Download Result\n",
        "\n",
        "if mode == 'preprocess_only':\n",
        "  if preprocess == 'nncp':\n",
        "    download('data/dictionary.words')\n",
        "  download(input_path)\n",
        "elif mode != 'decompress':\n",
        "  download('data/compressed.dat')\n",
        "  if preprocess == 'nncp':\n",
        "    download('data/dictionary.words')\n",
        "  if checkpoint and mode != \"both\":\n",
        "    download('data/model.index')\n",
        "    download('data/model.data-00000-of-00001')\n",
        "    download('data/checkpoint')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2hIA7_R5F2m"
      },
      "source": [
        "## Decompress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hZkjku3phchb"
      },
      "outputs": [],
      "source": [
        "#@title Decompression\n",
        "\n",
        "if mode == 'decompress' or mode == 'both':\n",
        "  output_path = \"data/decompressed.dat\"\n",
        "  with open(path_to_file, \"rb\") as inp, open(output_path, \"wb\") as out:\n",
        "    # Read the original file size from the header.\n",
        "    length = int.from_bytes(inp.read()[:5], byteorder='big')\n",
        "    inp.seek(5)\n",
        "    # Create a list to store the file characters.\n",
        "    output = [0] * length\n",
        "    bitin = BitInputStream(inp)\n",
        "    if preprocess == 'nncp' or preprocess == 'nncp-done':\n",
        "      # If the preprocessor is NNCP, we can get the vocab_size from the\n",
        "      # dictionary.\n",
        "      vocab_size = int(subprocess.check_output(\n",
        "          ['wc', '-l', 'data/dictionary.words']).split()[0])\n",
        "    else:\n",
        "      # If the preprocessor is not NNCP, we can get the vocabulary from the file\n",
        "      # header.\n",
        "      vocab = []\n",
        "      for i in range(256):\n",
        "        if bitin.read():\n",
        "          vocab.append(i)\n",
        "      vocab_size = len(vocab)\n",
        "    # Round up to a multiple of 8 to improve performance.\n",
        "    vocab_size = math.ceil(vocab_size/8) * 8\n",
        "    dec = ArithmeticDecoder(32, bitin)\n",
        "    process(False, length, vocab_size, dec, output)\n",
        "    # The decompressed data is stored in the \"output\" list. We can now write the\n",
        "    # data to file (based on the type of preprocessing used).\n",
        "    if preprocess == 'nncp' or preprocess == 'nncp-done':\n",
        "      for i in range(length):\n",
        "        out.write(bytes(((output[i] // 256),)))\n",
        "        out.write(bytes(((output[i] % 256),)))\n",
        "    else:\n",
        "      # Convert indexes back to the original characters.\n",
        "      idx2char = np.array(vocab)\n",
        "      for i in range(length):\n",
        "        out.write(bytes((idx2char[output[i]],)))\n",
        "\n",
        "  if preprocess == 'cmix':\n",
        "    !./cmix/cmix -d ./cmix/dictionary/english.dic $output_path ./data/final.dat\n",
        "    output_path = \"data/final.dat\"\n",
        "  if preprocess == 'nncp' or preprocess == 'nncp-done':\n",
        "    !./nncp-2019-11-16/preprocess d data/dictionary.words $output_path ./data/final.dat\n",
        "    output_path = \"data/final.dat\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ndF-mn69IJWF"
      },
      "outputs": [],
      "source": [
        "#@title Download Result\n",
        "\n",
        "if mode == 'decompress':\n",
        "  if preprocess == 'nncp-done':\n",
        "    download('data/decompressed.dat')\n",
        "  else:\n",
        "    download(output_path)\n",
        "  if checkpoint:\n",
        "    download('data/model.index')\n",
        "    download('data/model.data-00000-of-00001')\n",
        "    download('data/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5oyae1d9f0X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Validation\n",
        "!ls -l data\n",
        "if mode == 'decompress' or mode == 'both':\n",
        "  if preprocess == 'nncp-done':\n",
        "    !md5sum data/decompressed.dat\n",
        "  !md5sum $output_path\n",
        "if mode == 'both':\n",
        "  !md5sum $original_file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disconnect"
      ],
      "metadata": {
        "id": "7_ntLcnUb3uh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXpxZKLc-8HX"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
